{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nX_JaYRkb3Un"},"outputs":[],"source":["from google.colab import auth\n","import gspread\n","from google.auth import default\n","import pandas\n","import random\n","from numpy import int64\n","\n","auth.authenticate_user()\n","creds, _ = default()\n","gc = gspread.authorize(creds)\n","owner_emails = ['nickreid@gmail.com', 'pushkala.jayaraman@icahn.mssm.edu', 'gpratishtha17@gmail.com', 'teya.dragovic@gmail.com']\n","\n","def get_or_create_spreadsheet(worksheet_name):\n","  try:\n","    worksheet = gc.open(worksheet_name)\n","  except gspread.exceptions.SpreadsheetNotFound:\n","    worksheet = gc.create(worksheet_name)\n","    for _email in owner_emails:\n","      worksheet.share(_email, perm_type='user', role='writer')\n","  return worksheet\n","\n","def write_A1_query(df, offset=1):\n","  cols = [\n","    'ABCDEFGHIJKLMNOPQURSTUVWXYZ'[index]\n","    for index, col in enumerate(df.columns)\n","  ]\n","  return 'A{}:{}{}'.format(\n","    offset,\n","    cols[-1],\n","    len(df)+offset\n","  )\n","\n","def write_worksheet(df, spreadsheet, worksheet_name):\n","  df = remove_int64(df)\n","  worksheet = spreadsheet.worksheet(worksheet_name)\n","  worksheet.update(\n","      values = [\n","        df.columns.values.tolist()\n","      ] + [\n","        [\n","          value if not pandas.isnull(value) else ''\n","          for value in row\n","        ]\n","        for row in df.values.tolist()\n","      ],\n","      range_name = write_A1_query(df)\n","  )\n","\n","def remove_int64(df):\n","  return pandas.DataFrame(\n","    [\n","        [\n","            value if type(value) is not int64 else int(value)\n","            for value in row\n","        ]\n","        for row in df.values\n","    ],\n","    index = df.index,\n","    columns = df.columns\n","  )"]},{"cell_type":"code","source":["yir_spreadsheet = get_or_create_spreadsheet('2026 TBI YIR Spreadsheet')\n","articles = pandas.DataFrame(yir_spreadsheet.worksheet('Articles').get_all_records())\n","reviewers = pandas.DataFrame(yir_spreadsheet.worksheet('Reviewers').get_all_records())"],"metadata":{"id":"0Og4EB9AhimW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Update review assignments from each reviewer spreadsheet\n","yir_spreadsheet = gc.open('2026 TBI YIR Spreadsheet')\n","review_assignments = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Review Assignments').get_all_records()\n",")\n","\n","articles_to_add = []\n","\n","reviewer_initials = reviewers[reviewers['Articles to review']>0]['Initials'].tolist()\n","for _initials in reviewer_initials:\n","  reviewer_spreadsheet_name = '2026 AMIA TBI YIR - {}'.format(_initials)\n","  try:\n","    reviewer_spreadsheet = gc.open(reviewer_spreadsheet_name)\n","  except:\n","    print('Could not open spreadsheet for',_initials)\n","    continue\n","  try:\n","    reviewer_articles_to_screen = pandas.DataFrame(\n","      reviewer_spreadsheet.worksheet('Articles to review').get_all_records()\n","    )\n","  except:\n","    print('No articles to review worksheet for', _initials)\n","    continue\n","  for _, _article in reviewer_articles_to_screen.iterrows():\n","    if _article['PMID'] == \"\":\n","      print('empty PMID for ', _initials)\n","      continue\n","    recorded_article = review_assignments.query('PMID=={} and Initials==\"{}\"'.format(_article['PMID'], _initials))\n","    if len(recorded_article) == 0:\n","      articles_to_add.append({\n","          'PMID': _article['PMID'],\n","          'Initials': _initials,\n","          'First Author': _article['First Author'],\n","          'Title': _article['Title'],\n","          'Journal': _article['Journal'],\n","          'Informatics Novelty': _article['Informatics Novelty'],\n","          'Application Importance': _article['Application Importance'],\n","          'Presentability': _article['Presentability'],\n","          'Comments': _article['Comments']\n","      })\n","    elif len(recorded_article) == 1:\n","      _existing_index = recorded_article.index[0]\n","      review_assignments.loc[_existing_index, 'Informatics Novelty'] = _article['Informatics Novelty']\n","      review_assignments.loc[_existing_index, 'Application Importance'] = _article['Application Importance']\n","      review_assignments.loc[_existing_index, 'Presentability'] = _article['Presentability']\n","      review_assignments.loc[_existing_index, 'Comments'] = _article['Comments']\n","    else:\n","      print('WTF Multiple Records',_initials, _article['PMID'])\n","updated_assignments = pandas.concat(\n","    [\n","    review_assignments,\n","    pandas.DataFrame(articles_to_add)\n","    ]\n",")\n","updated_assignments.sort_values(['Initials', 'PMID'])\n","write_worksheet(updated_assignments, yir_spreadsheet, 'Review Assignments')"],"metadata":{"id":"aHDMbwYrQOym"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Update articles reviewed from review assignments\n","yir_spreadsheet = gc.open('2026 TBI YIR Spreadsheet')\n","review_assignments = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Review Assignments').get_all_records()\n",")\n","reviewers = pandas.DataFrame(yir_spreadsheet.worksheet('Reviewers').get_all_records())\n","\n","for _index, reviewer in reviewers.iterrows():\n","  reviewed_count = 0\n","  for _, review in review_assignments[review_assignments['Initials']==reviewer['Initials']].iterrows():\n","    if all([review[_key]!=\"\" for _key in ['Informatics Novelty', 'Application Importance','Presentability']]):\n","      reviewed_count += 1\n","  reviewers.loc[_index, \"Articles reviewed\"] = reviewed_count\n","\n","write_worksheet(reviewers, yir_spreadsheet, 'Reviewers')"],"metadata":{"id":"5D_x5vAQK4vr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Update reviewed articles from screened articles\n","screened_articles = pandas.DataFrame(\n","  yir_spreadsheet.worksheet('Screened Articles').get_all_records()\n",")\n","reviewed_articles = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Reviewed Articles').get_all_records()\n",")\n","\n","screened_articles_to_add = screened_articles[\n","    (screened_articles['Included'] == 'Yes')\n","    & ~(screened_articles['PMID'].isin(reviewed_articles['PMID']))\n","]\n","\n","updated_reviewed_articles = pandas.concat(\n","    [\n","      reviewed_articles,\n","      screened_articles_to_add[[\n","          'PMID', 'First Author', 'Title', 'Journal'\n","      ]]\n","    ]\n",")\n","updated_reviewed_articles['PubMed Link'] = [\n","  articles[articles['PMID']==pmid]['PubMed Link'].iloc[0] if pmid in articles['PMID'].tolist() else \"\"\n","  for pmid in updated_reviewed_articles['PMID']\n","]\n","write_worksheet(updated_reviewed_articles, yir_spreadsheet, 'Reviewed Articles')"],"metadata":{"id":"VRhiu_eUGSB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add scores to reviewed articles\n","review_assignments = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Review Assignments').get_all_records()\n",")\n","reviewed_articles = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Reviewed Articles').get_all_records()\n",")\n","\n","for index, article in reviewed_articles.iterrows():\n","  complete_reviews = []\n","  for _, _review in review_assignments[review_assignments['PMID']==article['PMID']].iterrows():\n","    if \"\" not in [_review[_key] for _key in ['Informatics Novelty', 'Application Importance','Presentability']]:\n","      complete_reviews.append({\n","          'Initials': _review['Initials'],\n","          'Informatics Novelty': _review['Informatics Novelty'],\n","          'Application Importance': _review['Application Importance'],\n","          'Presentability': _review['Presentability'],\n","          'Comments':_review['Comments']\n","      })\n","  if complete_reviews:\n","    reviewed_articles.loc[index, 'Reviewed By'] = \", \".join(\n","        [r['Initials'] for r in complete_reviews]\n","    )\n","    review_comments = []\n","    for r in complete_reviews:\n","      if r['Comments'] != \"\":\n","        review_comments.append(\"({}) {}\".format(\n","            r['Initials'],\n","            r['Comments']\n","        ))\n","    reviewed_articles.loc[index, 'Comments'] = \"\\n\".join(review_comments)\n","    for _key in ['Informatics Novelty', 'Application Importance','Presentability']:\n","      reviewed_articles.loc[index, _key] = pandas.Series(\n","          [r[_key] for r in complete_reviews if r[_key] != \"\"]\n","      ).mean()\n","\n","write_worksheet(reviewed_articles, yir_spreadsheet, 'Reviewed Articles')"],"metadata":{"id":"EnOaWUNfP5Hm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assign articles to review\n","reviewed_articles = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Reviewed Articles').get_all_records()\n",")\n","reviewer_assignments = pandas.DataFrame(\n","    yir_spreadsheet.worksheet('Review Assignments').get_all_records()\n",")\n","reviewers = pandas.DataFrame(yir_spreadsheet.worksheet('Reviewers').get_all_records())\n","# reviewers = reviewers[reviewers['Initials'].isin(['PJ'])]\n","\n","\n","for _, reviewer in reviewers.iterrows():\n","  articles_assigned_to_review = reviewer_assignments[\n","      reviewer_assignments['Initials'] == reviewer['Initials']\n","  ]\n","  articles_to_assign = reviewer['Articles to review'] - len(articles_assigned_to_review)\n","  if articles_to_assign > 0:\n","    print('Assign {} to {}'.format(articles_to_assign, reviewer['Initials']))\n","    possible_articles_to_assign = []\n","    for article_id in reviewed_articles['PMID']:\n","      if article_id in articles_assigned_to_review['PMID'].tolist():\n","        continue\n","      if sum(reviewer_assignments['PMID']==article_id) >= 1:\n","        continue\n","      possible_articles_to_assign.append(article_id)\n","    if len(possible_articles_to_assign) == 0:\n","      print('No articles to assign to {}'.format(reviewer['Initials']))\n","    if len(possible_articles_to_assign) < articles_to_assign:\n","      articles_to_assign = len(possible_articles_to_assign)\n","    for article_id in random.sample(possible_articles_to_assign, articles_to_assign):\n","      article = reviewed_articles.query('PMID=={}'.format(article_id)).iloc[0]\n","      reviewer_assignments = pandas.concat([\n","          reviewer_assignments,\n","          pandas.DataFrame([{\n","              'PMID': article_id,\n","              'Title': article['Title'],\n","              'First Author': article['First Author'],\n","              'Journal': article['Journal'],\n","              'PubMed Link': article['PubMed Link'],\n","              'Initials': reviewer['Initials']\n","          }])\n","      ])\n","\n","reviewer_assignments.sort_values(['Initials', 'PMID'], inplace=True)\n","write_worksheet(reviewer_assignments, yir_spreadsheet, 'Review Assignments')\n","\n","# Write screening assignments to individual spreadsheets if missing\n","for _initials in reviewer_assignments['Initials'].unique():\n","  reviewer_spreadsheet_name = '2026 AMIA TBI YIR - {}'.format(_initials)\n","  try:\n","    reviewer_spreadsheet = gc.open(reviewer_spreadsheet_name)\n","  except:\n","    print(_initials, 'could not open spreadsheet')\n","    continue\n","  try:\n","    reviewer_worksheet = reviewer_spreadsheet.worksheet('Articles to review')\n","  except:\n","    reviewer_spreadsheet.add_worksheet(\"Articles to review\", 10, 10)\n","  try:\n","    existing_review_articles = pandas.DataFrame(\n","        reviewer_spreadsheet.worksheet('Articles to review').get_all_records()\n","    )\n","  except:\n","    print(_initials, 'no existing review articles')\n","    existing_review_articles = pandas.DataFrame()\n","  articles_to_add = []\n","  for _, _article in reviewer_assignments.query('Initials==\"{}\"'.format(_initials)).iterrows():\n","    if 'PMID' not in existing_review_articles or _article['PMID'] not in existing_review_articles['PMID'].tolist():\n","      articles_to_add.append(_article)\n","  if articles_to_add:\n","    reviewer_screening_articles = pandas.concat(\n","        [\n","            existing_review_articles,\n","            pandas.DataFrame(articles_to_add)[[col for col in reviewer_assignments.columns if col != 'Initials']]\n","        ]\n","    )\n","    write_worksheet(reviewer_screening_articles, reviewer_spreadsheet, 'Articles to review')"],"metadata":{"id":"stMC0b6AUKHt"},"execution_count":null,"outputs":[]}]}